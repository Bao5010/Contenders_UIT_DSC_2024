{
    "info": {
        "name": "DynRT",
        "log": {
            "name": ""
        },
        "device": [
            0
        ],
        "test_on_checkpoint": "none",
        "train_on_checkpoint": "none"
    },
    "opt": {
        "seed": 2,
        "dataloader": {
            "requires": {
                "tokenizer_roberta": {
                    "path": "vinai/phobert-base-v2"
                }
            },
            "loaders": {
                "text": {
                    "data_path": "input/prepared_clean/",
                    "len": 256,
                    "pad": 1
                },
                "img": {
                    "data_path": "input/prepared_clean/",
                    "transform_image": "image_tensor/"
                },
                "label": {
                    "data_path": "input/prepared_clean/",
                    "test_label": true
                }
            },
            "batch_size": 8,
            "pin_memory": true,
            "num_workers": 0,
            "shuffle": true
        },
        "mode": [
            "train",
            "valid",
            "test"
        ],
        "checkpoint_step": 50,
        "modelopt": {
            "name": "DynRT",
            "input1": "text",
            "input2": "img",
            "input3": "text_mask",
            "layer": 6,
            "tau_max": 10,
            "ORDERS": [
                0,
                1,
                2,
                3,
                4,
                5
            ],
            "IMG_SCALE": 12,
            "dropout": 0.3,
            "hidden_size": 768,
            "ffn_size": 1024,
            "multihead": 2,
            "routing": "soft",
            "BINARIZE": false,
            "len": 256,
            "glimpses": 1,
            "output_size": 1024,
            "orders": 4,
            "pooling": "avg",
            "classifier": "both",
            "roberta_path": "vinai/phobert-base-v2",
            "roberta_layer": 1,
            "vitmodel": "vit_base_patch32_384",
            "finetune": false
        },
        "optimizeropt": {
            "name": "AdamW",
            "lr": 1e-4,
            "weight_decay": 0.1,
            "params": {
                "bertl_text": {
                    "lr": 3e-6
                },
                "vit": {
                    "lr": 3e-6,
                    "weight_decay": 0.1
                },
                "trar": {
                    "lr": 1e-5,
                    "weight_decay": 0.1
                },
                "classifier": {}
            }
        },
        "lossopt": {
            "name": "CrossEntropyLoss"
        },
        "total_epoch": 40,
        "clip": 2
    }
}